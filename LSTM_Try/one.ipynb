{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from music21 import converter, instrument, note, chord\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_files(midi_folder):\n",
    "    notes = []\n",
    "    for file in os.listdir(midi_folder):\n",
    "        midi = converter.parse(os.path.join(midi_folder, file))\n",
    "        notes_to_parse = None\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    return notes\n",
    "\n",
    "notes = load_midi_files('indian_classical')\n",
    "pitchnames = sorted(set(notes))\n",
    "note_to_int = {note: num for num, note in enumerate(pitchnames)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare sequences\n",
    "sequence_length = 100\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(len(notes) - sequence_length):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "network_input = np.reshape(network_input, (len(network_input), sequence_length, 1))\n",
    "network_input = torch.tensor(network_input / float(len(pitchnames)), dtype=torch.float32)\n",
    "network_output = torch.tensor(network_output, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(network_input, network_output)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '0.1': 1, '0.1.3': 2, '0.2': 3, '0.3': 4, '1': 5, '1.2': 6, '1.2.3': 7, '1.3': 8, '1.4': 9, '1.5': 10, '1.6': 11, '10': 12, '10.0': 13, '10.1': 14, '10.11': 15, '10.11.1': 16, '10.2': 17, '10.3': 18, '11': 19, '11.0': 20, '11.1': 21, '11.3': 22, '2': 23, '2.3': 24, '2.4': 25, '3': 26, '3.4': 27, '3.5': 28, '3.5.6': 29, '3.6': 30, '3.6.8': 31, '3.7': 32, '3.8': 33, '4': 34, '4.5': 35, '4.6': 36, '4.6.8': 37, '5': 38, '5.10': 39, '5.6': 40, '5.6.8': 41, '5.7': 42, '5.8': 43, '6': 44, '6.10': 45, '6.11': 46, '6.7': 47, '6.8': 48, '6.8.11': 49, '6.9': 50, '7': 51, '7.10': 52, '7.11': 53, '7.8': 54, '7.9': 55, '7.9.1': 56, '8': 57, '8.0': 58, '8.1': 59, '8.10': 60, '8.10.0': 61, '8.11': 62, '8.9': 63, '8.9.10': 64, '9': 65, '9.0': 66, '9.0.1': 67, '9.1': 68, '9.10': 69, '9.11': 70, '9.2': 71, 'A3': 72, 'A4': 73, 'A5': 74, 'B-3': 75, 'B-4': 76, 'B-5': 77, 'B2': 78, 'B3': 79, 'B4': 80, 'B5': 81, 'C#3': 82, 'C#4': 83, 'C#5': 84, 'C#6': 85, 'C3': 86, 'C4': 87, 'C5': 88, 'C6': 89, 'D1': 90, 'D2': 91, 'D3': 92, 'D4': 93, 'D5': 94, 'D6': 95, 'E-2': 96, 'E-3': 97, 'E-4': 98, 'E-5': 99, 'E-6': 100, 'E2': 101, 'E3': 102, 'E4': 103, 'E5': 104, 'E6': 105, 'F#2': 106, 'F#3': 107, 'F#4': 108, 'F#5': 109, 'F#6': 110, 'F1': 111, 'F3': 112, 'F4': 113, 'F5': 114, 'F6': 115, 'G#1': 116, 'G#2': 117, 'G#3': 118, 'G#4': 119, 'G#5': 120, 'G#6': 121, 'G3': 122, 'G4': 123, 'G5': 124, 'G6': 125}\n"
     ]
    }
   ],
   "source": [
    "print(note_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MusicLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, num_layers=3, dropout=0.1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  # Get the last time step output\n",
    "        return x\n",
    "\n",
    "model = MusicLSTM(1, 512, len(pitchnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrah-m\u001b[0m (\u001b[33mrebot\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\SEM6\\DL\\PROJ\\BEGIN\\wandb\\run-20240509_035343-nre94lyu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rebot/music-generation/runs/nre94lyu' target=\"_blank\">tough-star-1</a></strong> to <a href='https://wandb.ai/rebot/music-generation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rebot/music-generation' target=\"_blank\">https://wandb.ai/rebot/music-generation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rebot/music-generation/runs/nre94lyu' target=\"_blank\">https://wandb.ai/rebot/music-generation/runs/nre94lyu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 3.875348180839696\n",
      "Epoch 2/200, Loss: 3.8196415065490092\n",
      "Epoch 3/200, Loss: 3.8186707656408094\n",
      "Epoch 4/200, Loss: 3.8176115714397625\n",
      "Epoch 5/200, Loss: 3.8160945902165677\n",
      "Epoch 6/200, Loss: 3.8151123191892484\n",
      "Epoch 7/200, Loss: 3.814529764283564\n",
      "Epoch 8/200, Loss: 3.8147426487244283\n",
      "Epoch 9/200, Loss: 3.81422546475204\n",
      "Epoch 10/200, Loss: 3.813719758053416\n",
      "Epoch 11/200, Loss: 3.813046283328656\n",
      "Epoch 12/200, Loss: 3.813287932848193\n",
      "Epoch 13/200, Loss: 3.8133054013104783\n",
      "Epoch 14/200, Loss: 3.8125724288606153\n",
      "Epoch 15/200, Loss: 3.8131229680838046\n",
      "Epoch 16/200, Loss: 3.8126351354048422\n",
      "Epoch 17/200, Loss: 3.812126534501302\n",
      "Epoch 18/200, Loss: 3.8116091268578756\n",
      "Epoch 19/200, Loss: 3.811572591054071\n",
      "Epoch 20/200, Loss: 3.812893305857157\n",
      "Epoch 21/200, Loss: 3.8119275545336535\n",
      "Epoch 22/200, Loss: 3.8117403787435946\n",
      "Epoch 23/200, Loss: 3.810615765679743\n",
      "Epoch 24/200, Loss: 3.8112491123455086\n",
      "Epoch 25/200, Loss: 3.8112189425635585\n",
      "Epoch 26/200, Loss: 3.810680207517958\n",
      "Epoch 27/200, Loss: 3.8103754999711343\n",
      "Epoch 28/200, Loss: 3.8109192319752014\n",
      "Epoch 29/200, Loss: 3.810229343237336\n",
      "Epoch 30/200, Loss: 3.810634107933831\n",
      "Epoch 31/200, Loss: 3.8111941740684903\n",
      "Epoch 32/200, Loss: 3.810385900674407\n",
      "Epoch 33/200, Loss: 3.809816676316802\n",
      "Epoch 34/200, Loss: 3.809608605719104\n",
      "Epoch 35/200, Loss: 3.8100278684773397\n",
      "Epoch 36/200, Loss: 3.8098902935834276\n",
      "Epoch 37/200, Loss: 3.810093978016647\n",
      "Epoch 38/200, Loss: 3.809407709800091\n",
      "Epoch 39/200, Loss: 3.8100857206226624\n",
      "Epoch 40/200, Loss: 3.8097319664414395\n",
      "Epoch 41/200, Loss: 3.8095273307918274\n",
      "Epoch 42/200, Loss: 3.808907478126054\n",
      "Epoch 43/200, Loss: 3.809828731202588\n",
      "Epoch 44/200, Loss: 3.809281688375571\n",
      "Epoch 45/200, Loss: 3.8094481524732924\n",
      "Epoch 46/200, Loss: 3.8099086124872423\n",
      "Epoch 47/200, Loss: 3.8090901804953505\n",
      "Epoch 48/200, Loss: 3.8092465609619297\n",
      "Epoch 49/200, Loss: 3.8089106144364346\n",
      "Epoch 50/200, Loss: 3.808810080449606\n",
      "Epoch 51/200, Loss: 3.8079617429025396\n",
      "Epoch 52/200, Loss: 3.8087124775365457\n",
      "Epoch 53/200, Loss: 3.8086766078300083\n",
      "Epoch 54/200, Loss: 3.808525591781459\n",
      "Epoch 55/200, Loss: 3.8087942895201063\n",
      "Epoch 56/200, Loss: 3.8089901012243685\n",
      "Epoch 57/200, Loss: 3.8091835324297247\n",
      "Epoch 58/200, Loss: 3.8087749309146526\n",
      "Epoch 59/200, Loss: 3.8079237348025607\n",
      "Epoch 60/200, Loss: 3.8085133058508647\n",
      "Epoch 61/200, Loss: 3.808542297058499\n",
      "Epoch 62/200, Loss: 3.8086619192791966\n",
      "Epoch 63/200, Loss: 3.808108729185517\n",
      "Epoch 64/200, Loss: 3.8084534332924282\n",
      "Epoch 65/200, Loss: 3.808000976277381\n",
      "Epoch 66/200, Loss: 3.808146415297518\n",
      "Epoch 67/200, Loss: 3.807994203469188\n",
      "Epoch 68/200, Loss: 3.8079795050866827\n",
      "Epoch 69/200, Loss: 3.8079719875276705\n",
      "Epoch 70/200, Loss: 3.8082156095308126\n",
      "Epoch 71/200, Loss: 3.8086272797633693\n",
      "Epoch 72/200, Loss: 3.808071210212314\n",
      "Epoch 73/200, Loss: 3.807765050032704\n",
      "Epoch 74/200, Loss: 3.8080484178877367\n",
      "Epoch 75/200, Loss: 3.807773967379147\n",
      "Epoch 76/200, Loss: 3.8079720317702934\n",
      "Epoch 77/200, Loss: 3.807899486158312\n",
      "Epoch 78/200, Loss: 3.8075970448169514\n",
      "Epoch 79/200, Loss: 3.8069396682621277\n",
      "Epoch 80/200, Loss: 3.80768810105078\n",
      "Epoch 81/200, Loss: 3.807737302534359\n",
      "Epoch 82/200, Loss: 3.8080602478735224\n",
      "Epoch 83/200, Loss: 3.8084577629246663\n",
      "Epoch 84/200, Loss: 3.807296847559742\n",
      "Epoch 85/200, Loss: 3.807312611452083\n",
      "Epoch 86/200, Loss: 3.8075394458377483\n",
      "Epoch 87/200, Loss: 3.8070932282614955\n",
      "Epoch 88/200, Loss: 3.808355788594669\n",
      "Epoch 89/200, Loss: 3.8073957568591403\n",
      "Epoch 90/200, Loss: 3.807706062326726\n",
      "Epoch 91/200, Loss: 3.8064363998236117\n",
      "Epoch 92/200, Loss: 3.8073875990110575\n",
      "Epoch 93/200, Loss: 3.8078582594075154\n",
      "Epoch 94/200, Loss: 3.8076556011573555\n",
      "Epoch 95/200, Loss: 3.8075100146618084\n",
      "Epoch 96/200, Loss: 3.8080982658051954\n",
      "Epoch 97/200, Loss: 3.8073333071679185\n",
      "Epoch 98/200, Loss: 3.806541646878744\n",
      "Epoch 99/200, Loss: 3.806948239041358\n",
      "Epoch 100/200, Loss: 3.8071794509887695\n",
      "Epoch 101/200, Loss: 3.8070099329211047\n",
      "Epoch 102/200, Loss: 3.806797225450732\n",
      "Epoch 103/200, Loss: 3.8065392639219144\n",
      "Epoch 104/200, Loss: 3.8078145243457913\n",
      "Epoch 105/200, Loss: 3.807159590966923\n",
      "Epoch 106/200, Loss: 3.8068120393556417\n",
      "Epoch 107/200, Loss: 3.8071263684439907\n",
      "Epoch 108/200, Loss: 3.807285064274503\n",
      "Epoch 109/200, Loss: 3.806804103949635\n",
      "Epoch 110/200, Loss: 3.8070139688314852\n",
      "Epoch 111/200, Loss: 3.8070204331702793\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SEM6\\DL\\PROJ\\BEGIN\\one.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mavg_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m: epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: avg_loss})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m train_model(model, dataloader, \u001b[39m200\u001b[39;49m)\n",
      "\u001b[1;32md:\\SEM6\\DL\\PROJ\\BEGIN\\one.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mavg_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    \n",
    "    wandb.init(project=\"music-generation\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss}')\n",
    "        wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss})\n",
    "        \n",
    "train_model(model, dataloader, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\SEM6\\DL\\PROJ\\BEGIN\\one.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction_output\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Generate a piece of music\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m generated_notes \u001b[39m=\u001b[39m generate_music(model, network_input, pitchnames, note_to_int)\n",
      "\u001b[1;32md:\\SEM6\\DL\\PROJ\\BEGIN\\one.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Generate notes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m note_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_generate):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     prediction_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([pattern], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     prediction \u001b[39m=\u001b[39m model(prediction_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/one.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     _, index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(prediction, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: not a sequence"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_music(model, network_input, pitchnames, note_to_int, num_generate=500):\n",
    "    \"\"\" Generate music given a sequence of notes \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Pick a random sequence from the input as a starting point for the generation\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "    int_to_note = {num: note for note, num in note_to_int.items()}\n",
    "    pattern = network_input[start].tolist()\n",
    "    prediction_output = []\n",
    "\n",
    "    # Generate notes\n",
    "    for note_index in range(num_generate):\n",
    "        prediction_input = torch.tensor([pattern], dtype=torch.float32).to(device)\n",
    "        prediction = model(prediction_input)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        \n",
    "        result = int_to_note[index.item()]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern.append(index.item() / float(len(pitchnames)))\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "# Generate a piece of music\n",
    "generated_notes = generate_music(model, network_input, pitchnames, note_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note, chord, midi\n",
    "\n",
    "def create_midi(prediction_output, output_path='output.mid'):\n",
    "    \"\"\" Convert the output from the prediction to MIDI file \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # Create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # Pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # Pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # Increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=output_path)\n",
    "\n",
    "# Create a MIDI file from the generated notes\n",
    "create_midi(generated_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
