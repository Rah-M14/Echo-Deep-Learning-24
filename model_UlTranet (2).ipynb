{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMFJKSlhZhhz",
        "outputId": "d4a7e0d7-952f-4447-dde7-f572062cf254"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 10 19:07:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0              47W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CUHZ1SsZhdT",
        "outputId": "2f2638ac-2afd-4d4f-9393-b8ef1f809f60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiZ3C8xEZhZS",
        "outputId": "c90e8bc1-0119-48f9-afac-f6fc49199b1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchvggish"
      ],
      "metadata": {
        "id": "N0Lo95cybAmR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_zKRzLYZhWu",
        "outputId": "715bc369-5957-4312-ffce-ab4e5a91973a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.1.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-UGCAZUZhUM",
        "outputId": "a8899f82-d050-48b5-a21f-6bb77cb9ef03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrah-m\u001b[0m (\u001b[33mrebot\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "PtmlOTEaZNc4",
        "outputId": "1a01948b-b372-4c42-c9fd-cff92293905c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchaudio)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchaudio) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrah-m\u001b[0m (\u001b[33mrebot\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240510_190834-lyu28y9z</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rebot/UlTraNet/runs/lyu28y9z' target=\"_blank\">autumn-silence-22</a></strong> to <a href='https://wandb.ai/rebot/UlTraNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rebot/UlTraNet' target=\"_blank\">https://wandb.ai/rebot/UlTraNet</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rebot/UlTraNet/runs/lyu28y9z' target=\"_blank\">https://wandb.ai/rebot/UlTraNet/runs/lyu28y9z</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rebot/UlTraNet/runs/lyu28y9z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7d3d0f0fba60>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "!pip install torchaudio\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import wandb\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import Compose\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "wandb.init(project='UlTraNet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TUoJQEPGZNc7"
      },
      "outputs": [],
      "source": [
        "def load_audio(audio_path, sample_rate=22050, duration=5):\n",
        "    # Load audio file with librosa, automatically resampling to the given sample rate\n",
        "    audio, sr = librosa.load(audio_path, sr=sample_rate, duration=duration)\n",
        "\n",
        "    # Calculate target number of samples\n",
        "    target_length = sample_rate * duration\n",
        "\n",
        "    # Pad audio if it is shorter than the target length\n",
        "    if len(audio) < target_length:\n",
        "        padding = target_length - len(audio)\n",
        "        audio = np.pad(audio, (0, padding), mode='constant')\n",
        "    # Truncate audio if it is longer than the target length\n",
        "    elif len(audio) > target_length:\n",
        "        audio = audio[:target_length]\n",
        "\n",
        "    return audio\n",
        "\n",
        "def get_spectrogram(audio, n_fft=2048, hop_length=512, max_length=130):\n",
        "    # Generate a spectrogram\n",
        "    spectrogram = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
        "    # Convert to magnitude (amplitude)\n",
        "    spectrogram = np.abs(spectrogram)\n",
        "\n",
        "    # Pad or truncate the spectrogram to ensure all are the same length\n",
        "    if spectrogram.shape[1] < max_length:\n",
        "        padding = max_length - spectrogram.shape[1]\n",
        "        spectrogram = np.pad(spectrogram, ((0, 0), (0, padding)), mode='constant')\n",
        "    else:\n",
        "        spectrogram = spectrogram[:, :max_length]\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, root_dir, sample_rate=22050, n_fft=2048, hop_length=512, max_length=130):\n",
        "        self.root_dir = root_dir\n",
        "        self.sample_rate = sample_rate\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        self.max_length = max_length\n",
        "        self.files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root_dir) for f in filenames if f.endswith('.mp3') or f.endswith('.wav')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.files[idx]\n",
        "        audio = load_audio(audio_path, self.sample_rate)\n",
        "        spectrogram = get_spectrogram(audio, self.n_fft, self.hop_length, self.max_length)\n",
        "        return audio, spectrogram\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "\n",
        "    data_folder_path = os.path.join('/content/drive/My Drive', 'DATA')\n",
        "    dataset = AudioDataset(root_dir=data_folder_path)\n",
        "    loader = DataLoader(dataset, batch_size=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibKLI-0ZZNc7",
        "outputId": "db928244-e46a-41c9-af20-4c055bd8f51e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(110250,)\n",
            "(1025, 130)\n"
          ]
        }
      ],
      "source": [
        "# print(dataset[0])\n",
        "# print((dataset[0][0]))\n",
        "print(dataset[0][0].shape)\n",
        "\n",
        "# print(dataset[0][1])\n",
        "print(dataset[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iIciPx3fZNc8"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    total_size = len(dataset)\n",
        "    train_size = int(total_size * train_ratio)\n",
        "    val_size = int(total_size * val_ratio)\n",
        "    test_size = total_size - train_size - val_size  # Ensure all data is used\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "data_folder_path = 'DATA'\n",
        "# dataset = AudioDataset(root_dir=data_folder_path)\n",
        "\n",
        "# Assuming 'dataset' is an instance of AudioDataset\n",
        "train_dataset, val_dataset, test_dataset = split_dataset(dataset)\n",
        "\n",
        "# Create DataLoaders for each dataset split\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "acKBsRW_ZNc8"
      },
      "outputs": [],
      "source": [
        "# # Try to fetch a single batch to see if it works\n",
        "# try:\n",
        "#     data = next(iter(train_loader))\n",
        "#     print(\"Single batch loaded successfully:\", data)\n",
        "# except Exception as e:\n",
        "#     print(\"Failed to load a batch:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyaLToA7ZNc8",
        "outputId": "e27c44a0-b278-40b8-d021-ea41d2740ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 407\n",
            "Validation set size: 87\n",
            "Test set size: 88\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v139fKELZNc9"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# # Load a pre-trained VGGish model for audio feature extraction\n",
        "# vggish = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
        "\n",
        "# # Define the Perceptual Loss using VGGish as the feature extractor\n",
        "# class PerceptualLoss(nn.Module):\n",
        "#     def __init__(self, feature_extractor):\n",
        "#         super(PerceptualLoss, self).__init__()\n",
        "#         self.feature_extractor = feature_extractor\n",
        "#         self.feature_extractor.eval()  # Set to evaluation mode\n",
        "\n",
        "#     def forward(self, generated_audio, target_audio):\n",
        "#         with torch.no_grad():\n",
        "#             real_features = self.feature_extractor(target_audio)\n",
        "#         generated_features = self.feature_extractor(generated_audio)\n",
        "#         loss = F.l1_loss(generated_features, real_features)\n",
        "#         return loss\n",
        "\n",
        "# perceptual_loss = PerceptualLoss(vggish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N60aYjblZNc9"
      },
      "outputs": [],
      "source": [
        "class MultiScaleSpectrogramLoss(nn.Module):\n",
        "    def __init__(self, scales=[1024, 2048, 4096]):\n",
        "        super(MultiScaleSpectrogramLoss, self).__init__()\n",
        "        self.scales = scales\n",
        "\n",
        "    def forward(self, generated_audio, target_audio):\n",
        "        loss = 0\n",
        "        for scale in self.scales:\n",
        "            # print(\"Scale:\", scale)\n",
        "            # print(generated_audio.shape)\n",
        "            # print(target_audio.shape)\n",
        "            gen_spec = torch.stft(generated_audio.squeeze(1), n_fft=scale, return_complex=True)\n",
        "            target_spec = torch.stft(target_audio.squeeze(1), n_fft=scale, return_complex=True)\n",
        "            loss += F.l1_loss(gen_spec.abs(), target_spec.abs())\n",
        "        return loss / len(self.scales)\n",
        "\n",
        "spectrogram_loss = MultiScaleSpectrogramLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oygfI7dvZNc-"
      },
      "outputs": [],
      "source": [
        "# For demonstration, let's assume we have a simple CNN as a discriminator\n",
        "class SimpleAudioDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleAudioDiscriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)  # Changed to Conv1d\n",
        "        self.num_features = 16 * 110250  # 16 channels, length preserved at 110250\n",
        "        self.fc1 = nn.Linear(self.num_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def intermediate_forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return x\n",
        "\n",
        "discriminator = SimpleAudioDiscriminator()\n",
        "\n",
        "class FeatureMatchingLoss(nn.Module):\n",
        "    def __init__(self, discriminator):\n",
        "        super(FeatureMatchingLoss, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.discriminator.eval()\n",
        "\n",
        "    def forward(self, generated_audio, target_audio):\n",
        "        with torch.no_grad():\n",
        "            real_features = self.discriminator.intermediate_forward(target_audio)\n",
        "        generated_features = self.discriminator.intermediate_forward(generated_audio)\n",
        "        loss = F.l1_loss(generated_features, real_features)\n",
        "        return loss\n",
        "\n",
        "feature_matching_loss = FeatureMatchingLoss(discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HBqTMTHrZNc-"
      },
      "outputs": [],
      "source": [
        "# Example of a composite loss\n",
        "class CompositeLoss(nn.Module):\n",
        "    def __init__(self, spectrogram_loss, feature_matching_loss):\n",
        "        super(CompositeLoss, self).__init__()\n",
        "        # self.perceptual_loss = perceptual_loss\n",
        "        self.spectrogram_loss = spectrogram_loss\n",
        "        self.feature_matching_loss = feature_matching_loss\n",
        "\n",
        "    def forward(self, generated_audio, target_audio):\n",
        "        # loss = (self.perceptual_loss(generated_audio, target_audio) +\n",
        "        loss = (self.spectrogram_loss(generated_audio, target_audio) +\n",
        "                self.feature_matching_loss(generated_audio, target_audio))\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, epoch, i):\n",
        "    checkpoint_path = f'TW_Checkpoint/model_TW_{epoch}_{i}.pt'\n",
        "    data_folder_path = os.path.join('/content/drive/My Drive', checkpoint_path)\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(data_folder_path), exist_ok=True)\n",
        "\n",
        "    # Save the model state\n",
        "    torch.save(model.state_dict(), data_folder_path)\n",
        "    print(f\"Checkpoint saved to {data_folder_path}\")"
      ],
      "metadata": {
        "id": "EjAkoeSbqeP5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z85VgN2IZNc-"
      },
      "outputs": [],
      "source": [
        "class UltimateTransformerWaveNet(nn.Module):\n",
        "    def __init__(self, audio_channels=1, spectrogram_channels=1025, num_channels=64, kernel_size=2, num_blocks=4, num_layers=10, num_heads=8):\n",
        "        super(UltimateTransformerWaveNet, self).__init__()\n",
        "        self.audio_conv = nn.Conv1d(audio_channels, num_channels, kernel_size=1)\n",
        "        self.spectrogram_conv = nn.Conv1d(spectrogram_channels, num_channels, kernel_size=1)\n",
        "\n",
        "        # Dilated convolutions with residual and skip connections for both streams\n",
        "        self.audio_dilated_convs = nn.ModuleList()\n",
        "        self.spectrogram_dilated_convs = nn.ModuleList()\n",
        "        self.audio_skip_convs = nn.ModuleList()\n",
        "        self.spectrogram_skip_convs = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            dilation = 2 ** i\n",
        "            self.audio_dilated_convs.append(nn.Conv1d(num_channels, num_channels, kernel_size, dilation=dilation, padding=dilation, groups=num_channels//16))\n",
        "            self.spectrogram_dilated_convs.append(nn.Conv1d(num_channels, num_channels, kernel_size, dilation=dilation, padding=dilation, groups=num_channels//16))\n",
        "            self.audio_skip_convs.append(nn.Conv1d(num_channels, num_channels, 1))\n",
        "            self.spectrogram_skip_convs.append(nn.Conv1d(num_channels, num_channels, 1))\n",
        "\n",
        "        # Multi-head attention for combining features\n",
        "        self.feature_attention = nn.MultiheadAttention(embed_dim=num_channels, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Transformer block with residual connection\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=num_channels, nhead=num_heads, dim_feedforward=num_channels * 4, batch_first=True),\n",
        "            num_layers=3)\n",
        "\n",
        "        # Output layers\n",
        "        self.final_conv1 = nn.Conv1d(num_channels, num_channels, 1)\n",
        "        self.final_conv2 = nn.Conv1d(num_channels, audio_channels, 1)\n",
        "\n",
        "        # Additional residual connection across the network\n",
        "        self.residual_conv = nn.Conv1d(num_channels, num_channels, 1)\n",
        "\n",
        "    def forward(self, audio, spectrogram):\n",
        "        # print(\"Original audio shape:\", audio.shape)\n",
        "        # print(\"Original spectrogram shape:\", spectrogram.shape)\n",
        "\n",
        "        audio_input = F.relu(self.audio_conv(audio))\n",
        "        spectrogram_input = F.relu(self.spectrogram_conv(spectrogram))\n",
        "        audio = audio_input\n",
        "        spectrogram = spectrogram_input\n",
        "\n",
        "        # print(\"Audio shape:\", audio.shape)\n",
        "        # print(\"Spectrogram shape:\", spectrogram.shape)\n",
        "\n",
        "        audio_skip = 0\n",
        "        spectrogram_skip = 0\n",
        "\n",
        "        # Process through dilated convolutions with residual and skip connections\n",
        "        i = 0\n",
        "        for audio_conv, audio_skip_conv, spectro_conv, spectro_skip_conv in zip(self.audio_dilated_convs, self.audio_skip_convs, self.spectrogram_dilated_convs, self.spectrogram_skip_convs):\n",
        "            # print(\"Audio conv shape:\", audio_conv.shape)\n",
        "            # print(\"Audio skip conv shape:\", audio_skip_conv.shape)\n",
        "            # print(\"Spectrogram conv shape:\", spectro_conv.shape)\n",
        "            # print(\"Spectrogram skip conv shape:\", spectro_skip_conv.shape)\n",
        "            t1 = F.relu(audio_conv(audio))\n",
        "            # print(\"relu shape:\", t1.shape)\n",
        "            # print(\"audio shape:\", audio.shape)\n",
        "            t1 = t1[:, :, : -(2**i)]\n",
        "            # print(\"Modified relu shape:\", t1.shape)\n",
        "            audio = t1 + audio\n",
        "\n",
        "            t2 = F.relu(spectro_conv(spectrogram))\n",
        "            # print(\"Spectrogram conv shape:\", t2.shape)\n",
        "            # print(\"Spectrogram shape:\", spectrogram.shape)\n",
        "            t2 = t2[:, :, :-(2**i)]\n",
        "            # print(\"Modified Spectrogram conv shape:\", t2.shape)\n",
        "\n",
        "            spectrogram = t2 + spectrogram\n",
        "            audio_skip += audio_skip_conv(audio)\n",
        "            spectrogram_skip += spectro_skip_conv(spectrogram)\n",
        "            i += 1\n",
        "\n",
        "        # print(\"Audio skip shape:\", audio_skip.shape)\n",
        "        # print(\"Spectrogram skip shape:\", spectrogram_skip.shape)\n",
        "\n",
        "        # Combine using multi-head attention\n",
        "        combined, _ = self.feature_attention(audio_skip.transpose(1, 2), spectrogram_skip.transpose(1, 2), spectrogram_skip.transpose(1, 2))\n",
        "        combined = combined.transpose(1, 2)\n",
        "\n",
        "        # print(\"Combined shape:\", combined.shape)\n",
        "\n",
        "        # Transformer processing with residual connection\n",
        "        combined = self.transformer(combined.transpose(1, 2)).transpose(1, 2) + self.residual_conv(combined)\n",
        "\n",
        "        # print(\"Combined shape Transformer:\", combined.shape)\n",
        "        # Final processing\n",
        "        x = F.relu(self.final_conv1(combined))\n",
        "        x = self.final_conv2(x)\n",
        "\n",
        "        # print(\"Final x: \", x.shape)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # def generate_audio(self, audio, spectrogram, sample_no, device='cpu'):\n",
        "    #     \"\"\"\n",
        "    #     Generate audio using the model and save it to a directory.\n",
        "\n",
        "    #     Args:\n",
        "    #     audio (torch.Tensor): The input audio tensor.\n",
        "    #     spectrogram (torch.Tensor): The input spectrogram tensor.\n",
        "    #     sample_no (int): The sample number to append to the filename.\n",
        "    #     device (str): The device to perform computation on.\n",
        "    #     \"\"\"\n",
        "    #     # Ensure the model is in evaluation mode\n",
        "    #     self.eval()\n",
        "    #     # Move inputs to the correct device\n",
        "    #     audio = audio.to(device)\n",
        "    #     spectrogram = spectrogram.to(device)\n",
        "    #     # Generate audio using the forward method\n",
        "    #     with torch.no_grad():\n",
        "    #         generated_audio = self.forward(audio, spectrogram)\n",
        "    #     # Ensure the output directory exists\n",
        "    #     # output_dir = 'gen_music'\n",
        "    #     output_dir = os.path.join('/content/drive/My Drive', 'gen_music')\n",
        "    #     os.makedirs(output_dir, exist_ok=True)\n",
        "    #     # Save the generated audio to a file\n",
        "    #     output_path = os.path.join(output_dir, f'ultranwav_{sample_no}.wav')\n",
        "    #     torch.save(generated_audio, output_path)\n",
        "    #     print(f\"Generated audio saved to {output_path}\")\n",
        "    #     # Optionally, return the path or the audio tensor for further use\n",
        "    #     return output_path\n",
        "\n",
        "    def generate_audio(self, audio, spectrogram, sample_no, device='cpu'):\n",
        "        self.eval()  # Ensure the model is in evaluation mode\n",
        "        audio = audio.to(device)\n",
        "        spectrogram = spectrogram.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated_audio = self.forward(audio, spectrogram)\n",
        "\n",
        "        # Normalize the audio to the range [-1, 1] for WAV file compatibility\n",
        "        generated_audio = generated_audio / torch.max(torch.abs(generated_audio))\n",
        "\n",
        "        # Ensure the output directory exists\n",
        "        output_dir = os.path.join('/content/drive/My Drive', 'gen_music')\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        # print(f\"Output directory ensured at {output_dir}.\")\n",
        "\n",
        "        # Save the generated audio to a WAV file\n",
        "        output_path = os.path.join(output_dir, f'ultranwav_{sample_no}.wav')\n",
        "\n",
        "        # Ensure the tensor is in the correct shape (channels, frames)\n",
        "        if generated_audio.squeeze(0).dim() == 1:\n",
        "            generated_audio = generated_audio.unsqueeze(0)  # Add channel dimension for mono\n",
        "        elif generated_audio.squeeze(0).dim() == 2:\n",
        "            pass  # Correct format\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported tensor shape for audio saving\")\n",
        "\n",
        "        # Set the sample rate and channel layout\n",
        "        sample_rate = 22050  # Adjust as needed\n",
        "        channels = generated_audio.shape[0]\n",
        "        channel_layout = 'mono' if channels == 1 else 'stereo'\n",
        "\n",
        "        # Save using torchaudio with the correct settings\n",
        "        torchaudio.save(output_path, generated_audio.squeeze(0).cpu(), sample_rate, format='wav', encoding='PCM_S', bits_per_sample=16)\n",
        "\n",
        "        print(f\"Generated audio saved to {output_path}\")\n",
        "        return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v3MOzMi9ZNc_"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, optimizer, criterion, epochs, device):\n",
        "    model.to(device)\n",
        "    print(device)\n",
        "    print(\"Training Begins!\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for i, (audio, spectrogram) in enumerate(train_loader):\n",
        "            audio, spectrogram = audio.to(device), spectrogram.to(device)\n",
        "\n",
        "            if audio.dim() == 2:\n",
        "                audio = audio.unsqueeze(1)  # Add channel dimension\n",
        "            elif audio.dim() != 3:\n",
        "                raise ValueError(\"Audio input must be 2D or 3D tensor\")\n",
        "\n",
        "            # print(\"Out here\")\n",
        "\n",
        "            # window = torch.hann_window(1024, device=device)\n",
        "            # spectrogram = torch.stft(spectrogram.squeeze(1), n_fft=1024, hop_length=256, win_length=1024, window=window, return_complex=True)\n",
        "            # spectrogram.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(audio, spectrogram)\n",
        "            # print(output.shape)\n",
        "            loss = criterion(output, audio)  # Ensure the criterion is correctly defined for the expected output\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Log loss to wandb\n",
        "            wandb.log({\"train_loss\": loss.item()})\n",
        "            if i % 1 == 0:  # Log every 10 steps\n",
        "                print(f\"Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item()}\")\n",
        "\n",
        "            # Save model checkpoint periodically or based on performance\n",
        "            if i % 1 == 0:  # Save every 100 iterations\n",
        "                save_checkpoint(model, epoch, i)\n",
        "                # synthetic_audio = model.generate_audio(audio, spectrogram, i, device)\n",
        "\n",
        "            # # # Generate synthetic data and add to train_loader if needed\n",
        "            # if i % 1 == 0:  # Generate synthetic data every 50 iterations\n",
        "            #     # with torch.no_grad():\n",
        "            #     synthetic_audio = model.generate_audio(audio, spectrogram, i, device)\n",
        "            # #         # Assuming train_loader.dataset is a list or supports append\n",
        "            # #         train_loader.dataset.append((synthetic_audio.detach(), spectrogram))\n",
        "\n",
        "        epoch_loss /= len(train_loader)\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Average Loss: {epoch_loss}\")\n",
        "        wandb.log({\"epoch_loss\": epoch_loss})\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for audio, spectrogram in val_loader:\n",
        "                audio, spectrogram = audio.to(device), spectrogram.to(device)\n",
        "                audio = audio.unsqueeze(1)\n",
        "                output = model(audio, spectrogram)\n",
        "                val_loss += criterion(output, audio).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        wandb.log({\"val_loss\": val_loss})\n",
        "        print(f\"Validation Loss: {val_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3au14-xvZNdA"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UltimateTransformerWaveNet().to(device)\n",
        "# print(model)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "# composite_loss = CompositeLoss(perceptual_loss, spectrogram_loss, feature_matching_loss)\n",
        "composite_loss = CompositeLoss(spectrogram_loss, feature_matching_loss).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTnreWS2ZNdA",
        "outputId": "cdd79403-57f0-46c7-9947-e74c2e8ed41f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Training Begins!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:660: UserWarning: A window was not provided. A rectangular window will be applied,which is known to cause spectral leakage. Other windows such as torch.hann_window or torch.hamming_window can are recommended to reduce spectral leakage.To suppress this warning and use a rectangular window, explicitly set `window=torch.ones(n_fft, device=<device>)`. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:837.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [1/41], Loss: 3.3143563270568848\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_0.pt\n",
            "Epoch [1/50], Step [2/41], Loss: 4.457818984985352\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_1.pt\n",
            "Epoch [1/50], Step [3/41], Loss: 3.0026683807373047\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_2.pt\n",
            "Epoch [1/50], Step [4/41], Loss: 5.681921005249023\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_3.pt\n",
            "Epoch [1/50], Step [5/41], Loss: 3.6221697330474854\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_4.pt\n",
            "Epoch [1/50], Step [6/41], Loss: 2.1675972938537598\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_5.pt\n",
            "Epoch [1/50], Step [7/41], Loss: 4.103199481964111\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_6.pt\n",
            "Epoch [1/50], Step [8/41], Loss: 2.5279550552368164\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_7.pt\n",
            "Epoch [1/50], Step [9/41], Loss: 2.517507314682007\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_8.pt\n",
            "Epoch [1/50], Step [10/41], Loss: 2.180678367614746\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_9.pt\n",
            "Epoch [1/50], Step [11/41], Loss: 3.410703659057617\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_10.pt\n",
            "Epoch [1/50], Step [12/41], Loss: 2.6852869987487793\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_11.pt\n",
            "Epoch [1/50], Step [13/41], Loss: 2.066950559616089\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_12.pt\n",
            "Epoch [1/50], Step [14/41], Loss: 2.1497373580932617\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_13.pt\n",
            "Epoch [1/50], Step [15/41], Loss: 2.824063301086426\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_14.pt\n",
            "Epoch [1/50], Step [16/41], Loss: 2.3885138034820557\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_15.pt\n",
            "Epoch [1/50], Step [17/41], Loss: 1.9959272146224976\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_16.pt\n",
            "Epoch [1/50], Step [18/41], Loss: 1.903582215309143\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_17.pt\n",
            "Epoch [1/50], Step [19/41], Loss: 1.7147876024246216\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_18.pt\n",
            "Epoch [1/50], Step [20/41], Loss: 2.6533243656158447\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_19.pt\n",
            "Epoch [1/50], Step [21/41], Loss: 2.0073840618133545\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_20.pt\n",
            "Epoch [1/50], Step [22/41], Loss: 2.202831745147705\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_21.pt\n",
            "Epoch [1/50], Step [23/41], Loss: 1.862992286682129\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_22.pt\n",
            "Epoch [1/50], Step [24/41], Loss: 2.01682448387146\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_23.pt\n",
            "Epoch [1/50], Step [25/41], Loss: 2.3371243476867676\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_24.pt\n",
            "Epoch [1/50], Step [26/41], Loss: 1.9302396774291992\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_25.pt\n",
            "Epoch [1/50], Step [27/41], Loss: 1.9016003608703613\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_26.pt\n",
            "Epoch [1/50], Step [28/41], Loss: 1.8786159753799438\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_27.pt\n",
            "Epoch [1/50], Step [29/41], Loss: 2.3086109161376953\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_28.pt\n",
            "Epoch [1/50], Step [30/41], Loss: 1.7111564874649048\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_29.pt\n",
            "Epoch [1/50], Step [31/41], Loss: 1.3631166219711304\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_30.pt\n",
            "Epoch [1/50], Step [32/41], Loss: 1.8622294664382935\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_31.pt\n",
            "Epoch [1/50], Step [33/41], Loss: 1.5578804016113281\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_32.pt\n",
            "Epoch [1/50], Step [34/41], Loss: 2.0679593086242676\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_33.pt\n",
            "Epoch [1/50], Step [35/41], Loss: 1.7690917253494263\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_34.pt\n",
            "Epoch [1/50], Step [36/41], Loss: 1.9678702354431152\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_35.pt\n",
            "Epoch [1/50], Step [37/41], Loss: 2.3020071983337402\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_36.pt\n",
            "Epoch [1/50], Step [38/41], Loss: 2.1950457096099854\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_37.pt\n",
            "Epoch [1/50], Step [39/41], Loss: 1.9777683019638062\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_38.pt\n",
            "Epoch [1/50], Step [40/41], Loss: 2.4322636127471924\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_39.pt\n",
            "Epoch [1/50], Step [41/41], Loss: 2.0419139862060547\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_0_40.pt\n",
            "Epoch [1/50], Average Loss: 2.416177461786968\n",
            "Validation Loss: 2.323329634136624\n",
            "Epoch [2/50], Step [1/41], Loss: 2.52712082862854\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_0.pt\n",
            "Epoch [2/50], Step [2/41], Loss: 2.0920424461364746\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_1.pt\n",
            "Epoch [2/50], Step [3/41], Loss: 2.4014596939086914\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_2.pt\n",
            "Epoch [2/50], Step [4/41], Loss: 1.3915200233459473\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_3.pt\n",
            "Epoch [2/50], Step [5/41], Loss: 1.872365117073059\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_4.pt\n",
            "Epoch [2/50], Step [6/41], Loss: 1.8090274333953857\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_5.pt\n",
            "Epoch [2/50], Step [7/41], Loss: 1.9238076210021973\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_6.pt\n",
            "Epoch [2/50], Step [8/41], Loss: 2.421189308166504\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_7.pt\n",
            "Epoch [2/50], Step [9/41], Loss: 2.1611692905426025\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_8.pt\n",
            "Epoch [2/50], Step [10/41], Loss: 2.223947525024414\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_9.pt\n",
            "Epoch [2/50], Step [11/41], Loss: 2.3373656272888184\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_10.pt\n",
            "Epoch [2/50], Step [12/41], Loss: 2.3504936695098877\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_11.pt\n",
            "Epoch [2/50], Step [13/41], Loss: 1.502880573272705\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_12.pt\n",
            "Epoch [2/50], Step [14/41], Loss: 1.2296062707901\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_13.pt\n",
            "Epoch [2/50], Step [15/41], Loss: 2.4174253940582275\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_14.pt\n",
            "Epoch [2/50], Step [16/41], Loss: 1.6445106267929077\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_15.pt\n",
            "Epoch [2/50], Step [17/41], Loss: 2.149082899093628\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_16.pt\n",
            "Epoch [2/50], Step [18/41], Loss: 1.5495903491973877\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_17.pt\n",
            "Epoch [2/50], Step [19/41], Loss: 1.513022780418396\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_18.pt\n",
            "Epoch [2/50], Step [20/41], Loss: 1.5724945068359375\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_19.pt\n",
            "Epoch [2/50], Step [21/41], Loss: 1.8290200233459473\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_20.pt\n",
            "Epoch [2/50], Step [22/41], Loss: 1.7023168802261353\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_21.pt\n",
            "Epoch [2/50], Step [23/41], Loss: 1.221189260482788\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_22.pt\n",
            "Epoch [2/50], Step [24/41], Loss: 1.4379239082336426\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_23.pt\n",
            "Epoch [2/50], Step [25/41], Loss: 1.6318618059158325\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_24.pt\n",
            "Epoch [2/50], Step [26/41], Loss: 1.9630833864212036\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_25.pt\n",
            "Epoch [2/50], Step [27/41], Loss: 2.119696855545044\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_26.pt\n",
            "Epoch [2/50], Step [28/41], Loss: 1.7678859233856201\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_27.pt\n",
            "Epoch [2/50], Step [29/41], Loss: 1.5194753408432007\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_28.pt\n",
            "Epoch [2/50], Step [30/41], Loss: 1.8970836400985718\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_29.pt\n",
            "Epoch [2/50], Step [31/41], Loss: 1.7889007329940796\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_30.pt\n",
            "Epoch [2/50], Step [32/41], Loss: 1.6860285997390747\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_31.pt\n",
            "Epoch [2/50], Step [33/41], Loss: 2.284743070602417\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_32.pt\n",
            "Epoch [2/50], Step [34/41], Loss: 1.2738115787506104\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_33.pt\n",
            "Epoch [2/50], Step [35/41], Loss: 1.2674719095230103\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_34.pt\n",
            "Epoch [2/50], Step [36/41], Loss: 1.8058247566223145\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_35.pt\n",
            "Epoch [2/50], Step [37/41], Loss: 1.3442121744155884\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_36.pt\n",
            "Epoch [2/50], Step [38/41], Loss: 1.8971184492111206\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_37.pt\n",
            "Epoch [2/50], Step [39/41], Loss: 2.072164535522461\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_38.pt\n",
            "Epoch [2/50], Step [40/41], Loss: 1.531265377998352\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_39.pt\n",
            "Epoch [2/50], Step [41/41], Loss: 1.2568143606185913\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_1_40.pt\n",
            "Epoch [2/50], Average Loss: 1.8143418184140834\n",
            "Validation Loss: 1.6043313609229193\n",
            "Epoch [3/50], Step [1/41], Loss: 1.4326269626617432\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_0.pt\n",
            "Epoch [3/50], Step [2/41], Loss: 1.0584616661071777\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_1.pt\n",
            "Epoch [3/50], Step [3/41], Loss: 1.4295103549957275\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_2.pt\n",
            "Epoch [3/50], Step [4/41], Loss: 1.096845269203186\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_3.pt\n",
            "Epoch [3/50], Step [5/41], Loss: 1.6388630867004395\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_4.pt\n",
            "Epoch [3/50], Step [6/41], Loss: 1.3586076498031616\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_5.pt\n",
            "Epoch [3/50], Step [7/41], Loss: 1.5153628587722778\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_6.pt\n",
            "Epoch [3/50], Step [8/41], Loss: 1.4099215269088745\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_7.pt\n",
            "Epoch [3/50], Step [9/41], Loss: 1.674480676651001\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_8.pt\n",
            "Epoch [3/50], Step [10/41], Loss: 1.7603576183319092\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_9.pt\n",
            "Epoch [3/50], Step [11/41], Loss: 0.9330477714538574\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_10.pt\n",
            "Epoch [3/50], Step [12/41], Loss: 1.729005217552185\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_11.pt\n",
            "Epoch [3/50], Step [13/41], Loss: 1.5199366807937622\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_12.pt\n",
            "Epoch [3/50], Step [14/41], Loss: 1.3714890480041504\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_13.pt\n",
            "Epoch [3/50], Step [15/41], Loss: 1.4057079553604126\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_14.pt\n",
            "Epoch [3/50], Step [16/41], Loss: 1.1655638217926025\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_15.pt\n",
            "Epoch [3/50], Step [17/41], Loss: 1.317671775817871\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_16.pt\n",
            "Epoch [3/50], Step [18/41], Loss: 1.2664453983306885\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_17.pt\n",
            "Epoch [3/50], Step [19/41], Loss: 1.5963389873504639\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_18.pt\n",
            "Epoch [3/50], Step [20/41], Loss: 1.0906559228897095\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_19.pt\n",
            "Epoch [3/50], Step [21/41], Loss: 1.3514913320541382\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_20.pt\n",
            "Epoch [3/50], Step [22/41], Loss: 1.3242857456207275\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_21.pt\n",
            "Epoch [3/50], Step [23/41], Loss: 0.8965303301811218\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_22.pt\n",
            "Epoch [3/50], Step [24/41], Loss: 1.3926700353622437\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_23.pt\n",
            "Epoch [3/50], Step [25/41], Loss: 1.5619075298309326\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_24.pt\n",
            "Epoch [3/50], Step [26/41], Loss: 1.4173238277435303\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_25.pt\n",
            "Epoch [3/50], Step [27/41], Loss: 1.052476167678833\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_26.pt\n",
            "Epoch [3/50], Step [28/41], Loss: 1.001427412033081\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_27.pt\n",
            "Epoch [3/50], Step [29/41], Loss: 1.1531316041946411\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_28.pt\n",
            "Epoch [3/50], Step [30/41], Loss: 1.5758010149002075\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_29.pt\n",
            "Epoch [3/50], Step [31/41], Loss: 1.9707422256469727\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_30.pt\n",
            "Epoch [3/50], Step [32/41], Loss: 0.9933242201805115\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_31.pt\n",
            "Epoch [3/50], Step [33/41], Loss: 1.7608513832092285\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_32.pt\n",
            "Epoch [3/50], Step [34/41], Loss: 1.9101276397705078\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_33.pt\n",
            "Epoch [3/50], Step [35/41], Loss: 1.5514028072357178\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_34.pt\n",
            "Epoch [3/50], Step [36/41], Loss: 1.4993027448654175\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_35.pt\n",
            "Epoch [3/50], Step [37/41], Loss: 1.4786202907562256\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_36.pt\n",
            "Epoch [3/50], Step [38/41], Loss: 1.4948009252548218\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_37.pt\n",
            "Epoch [3/50], Step [39/41], Loss: 1.1412107944488525\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_38.pt\n",
            "Epoch [3/50], Step [40/41], Loss: 1.1706815958023071\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_39.pt\n",
            "Epoch [3/50], Step [41/41], Loss: 1.4927679300308228\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_2_40.pt\n",
            "Epoch [3/50], Average Loss: 1.3893116538117571\n",
            "Validation Loss: 1.7143294943703546\n",
            "Epoch [4/50], Step [1/41], Loss: 1.5973976850509644\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_0.pt\n",
            "Epoch [4/50], Step [2/41], Loss: 1.432654619216919\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_1.pt\n",
            "Epoch [4/50], Step [3/41], Loss: 1.5716661214828491\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_2.pt\n",
            "Epoch [4/50], Step [4/41], Loss: 1.4325306415557861\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_3.pt\n",
            "Epoch [4/50], Step [5/41], Loss: 1.3399417400360107\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_4.pt\n",
            "Epoch [4/50], Step [6/41], Loss: 1.0936520099639893\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_5.pt\n",
            "Epoch [4/50], Step [7/41], Loss: 1.3578275442123413\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_6.pt\n",
            "Epoch [4/50], Step [8/41], Loss: 1.0703378915786743\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_7.pt\n",
            "Epoch [4/50], Step [9/41], Loss: 1.1037983894348145\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_8.pt\n",
            "Epoch [4/50], Step [10/41], Loss: 1.3418054580688477\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_9.pt\n",
            "Epoch [4/50], Step [11/41], Loss: 1.291334629058838\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_10.pt\n",
            "Epoch [4/50], Step [12/41], Loss: 1.331820011138916\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_11.pt\n",
            "Epoch [4/50], Step [13/41], Loss: 1.2576884031295776\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_12.pt\n",
            "Epoch [4/50], Step [14/41], Loss: 0.9600394368171692\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_13.pt\n",
            "Epoch [4/50], Step [15/41], Loss: 1.3013250827789307\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_14.pt\n",
            "Epoch [4/50], Step [16/41], Loss: 1.2793858051300049\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_15.pt\n",
            "Epoch [4/50], Step [17/41], Loss: 0.9571442604064941\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_16.pt\n",
            "Epoch [4/50], Step [18/41], Loss: 1.3733868598937988\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_17.pt\n",
            "Epoch [4/50], Step [19/41], Loss: 0.8949259519577026\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_18.pt\n",
            "Epoch [4/50], Step [20/41], Loss: 1.1765687465667725\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_19.pt\n",
            "Epoch [4/50], Step [21/41], Loss: 1.5533232688903809\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_20.pt\n",
            "Epoch [4/50], Step [22/41], Loss: 1.1509058475494385\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_21.pt\n",
            "Epoch [4/50], Step [23/41], Loss: 1.081588864326477\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_22.pt\n",
            "Epoch [4/50], Step [24/41], Loss: 1.0990203619003296\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_23.pt\n",
            "Epoch [4/50], Step [25/41], Loss: 1.1507182121276855\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_24.pt\n",
            "Epoch [4/50], Step [26/41], Loss: 0.9830014705657959\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_25.pt\n",
            "Epoch [4/50], Step [27/41], Loss: 1.5671695470809937\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_26.pt\n",
            "Epoch [4/50], Step [28/41], Loss: 1.432228922843933\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_27.pt\n",
            "Epoch [4/50], Step [29/41], Loss: 1.1218862533569336\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_28.pt\n",
            "Epoch [4/50], Step [30/41], Loss: 1.0559245347976685\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_29.pt\n",
            "Epoch [4/50], Step [31/41], Loss: 1.0744597911834717\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_30.pt\n",
            "Epoch [4/50], Step [32/41], Loss: 1.0005234479904175\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_31.pt\n",
            "Epoch [4/50], Step [33/41], Loss: 1.2894014120101929\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_32.pt\n",
            "Epoch [4/50], Step [34/41], Loss: 1.2015202045440674\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_33.pt\n",
            "Epoch [4/50], Step [35/41], Loss: 1.2309026718139648\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_34.pt\n",
            "Epoch [4/50], Step [36/41], Loss: 1.0794339179992676\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_35.pt\n",
            "Epoch [4/50], Step [37/41], Loss: 1.467746615409851\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_36.pt\n",
            "Epoch [4/50], Step [38/41], Loss: 1.1446170806884766\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_37.pt\n",
            "Epoch [4/50], Step [39/41], Loss: 1.0343064069747925\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_38.pt\n",
            "Epoch [4/50], Step [40/41], Loss: 0.934441089630127\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_39.pt\n",
            "Epoch [4/50], Step [41/41], Loss: 0.9219642281532288\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_3_40.pt\n",
            "Epoch [4/50], Average Loss: 1.213178425300412\n",
            "Validation Loss: 1.1087187727292378\n",
            "Epoch [5/50], Step [1/41], Loss: 0.9015117287635803\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_0.pt\n",
            "Epoch [5/50], Step [2/41], Loss: 1.022606372833252\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_1.pt\n",
            "Epoch [5/50], Step [3/41], Loss: 0.9420021176338196\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_2.pt\n",
            "Epoch [5/50], Step [4/41], Loss: 0.9410544633865356\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_3.pt\n",
            "Epoch [5/50], Step [5/41], Loss: 0.9674336314201355\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_4.pt\n",
            "Epoch [5/50], Step [6/41], Loss: 1.0737534761428833\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_5.pt\n",
            "Epoch [5/50], Step [7/41], Loss: 0.9415410161018372\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_6.pt\n",
            "Epoch [5/50], Step [8/41], Loss: 1.5442543029785156\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_7.pt\n",
            "Epoch [5/50], Step [9/41], Loss: 1.1079508066177368\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_8.pt\n",
            "Epoch [5/50], Step [10/41], Loss: 0.9926713705062866\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_9.pt\n",
            "Epoch [5/50], Step [11/41], Loss: 1.0562748908996582\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_10.pt\n",
            "Epoch [5/50], Step [12/41], Loss: 1.163299322128296\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_11.pt\n",
            "Epoch [5/50], Step [13/41], Loss: 1.2856450080871582\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_12.pt\n",
            "Epoch [5/50], Step [14/41], Loss: 1.0337607860565186\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_13.pt\n",
            "Epoch [5/50], Step [15/41], Loss: 0.814501941204071\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_14.pt\n",
            "Epoch [5/50], Step [16/41], Loss: 0.8149814605712891\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_15.pt\n",
            "Epoch [5/50], Step [17/41], Loss: 1.3203370571136475\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_16.pt\n",
            "Epoch [5/50], Step [18/41], Loss: 0.9566001892089844\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_17.pt\n",
            "Epoch [5/50], Step [19/41], Loss: 1.2707828283309937\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_18.pt\n",
            "Epoch [5/50], Step [20/41], Loss: 1.4161176681518555\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_19.pt\n",
            "Epoch [5/50], Step [21/41], Loss: 1.0723003149032593\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_20.pt\n",
            "Epoch [5/50], Step [22/41], Loss: 1.3417950868606567\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_21.pt\n",
            "Epoch [5/50], Step [23/41], Loss: 0.83247309923172\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_22.pt\n",
            "Epoch [5/50], Step [24/41], Loss: 0.9044559001922607\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_23.pt\n",
            "Epoch [5/50], Step [25/41], Loss: 1.4376660585403442\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_24.pt\n",
            "Epoch [5/50], Step [26/41], Loss: 0.9482653141021729\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_25.pt\n",
            "Epoch [5/50], Step [27/41], Loss: 0.7709957957267761\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_26.pt\n",
            "Epoch [5/50], Step [28/41], Loss: 0.8691762089729309\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_27.pt\n",
            "Epoch [5/50], Step [29/41], Loss: 1.0625097751617432\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_28.pt\n",
            "Epoch [5/50], Step [30/41], Loss: 0.6957269310951233\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_29.pt\n",
            "Epoch [5/50], Step [31/41], Loss: 0.6321821212768555\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_30.pt\n",
            "Epoch [5/50], Step [32/41], Loss: 0.9625754952430725\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_31.pt\n",
            "Epoch [5/50], Step [33/41], Loss: 0.6977244019508362\n",
            "Checkpoint saved to /content/drive/My Drive/TW_Checkpoint/model_TW_4_32.pt\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, val_loader, optimizer, composite_loss, epochs=50, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qahzPQwGZNdA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}