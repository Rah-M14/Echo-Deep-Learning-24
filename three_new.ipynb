{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from music21 import converter, instrument, note, chord\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\SEM6\\DL\\PROJ\\BEGIN\\three_new.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/three_new.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/three_new.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/three_new.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mvamp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/three_new.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpretty_midi\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SEM6/DL/PROJ/BEGIN/three_new.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_melody_to_midi\u001b[39m(source_folder, target_folder):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vamp'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import vamp\n",
    "import pretty_midi\n",
    "\n",
    "def extract_melody_to_midi(source_folder, target_folder):\n",
    "    for subdir, dirs, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            if filepath.endswith(\".mp3\") or filepath.endswith(\".wav\"):\n",
    "                print(f\"Processing file: {filepath}\")\n",
    "                \n",
    "                # Load audio file\n",
    "                y, sr = librosa.load(filepath, sr=None)\n",
    "                \n",
    "                # Extract melody using Melodia\n",
    "                params = {\"voicing\": 0.2}\n",
    "                melody, timestamps = vamp.collect(y, sr, \"mtg-melodia:melodia\", parameters=params)\n",
    "                pitch = melody['vector'][0]\n",
    "                \n",
    "                # Create a PrettyMIDI object\n",
    "                midi = pretty_midi.PrettyMIDI()\n",
    "                instrument = pretty_midi.Instrument(program=pretty_midi.instrument_name_to_program('Acoustic Grand Piano'))\n",
    "                \n",
    "                # Convert extracted pitch to notes\n",
    "                notes = [pretty_midi.Note(velocity=100, pitch=int(p), start=t, end=t+0.1) for p, t in zip(pitch, timestamps) if p > 0]\n",
    "                instrument.notes.extend(notes)\n",
    "                midi.instruments.append(instrument)\n",
    "                \n",
    "                # Ensure target directory exists\n",
    "                target_subdir = os.path.join(target_folder, os.path.basename(subdir) + \"_midi\")\n",
    "                if not os.path.exists(target_subdir):\n",
    "                    os.makedirs(target_subdir)\n",
    "                \n",
    "                # Save MIDI file\n",
    "                midi_file_path = os.path.join(target_subdir, file.replace('.mp3', '.mid').replace('.wav', '.mid'))\n",
    "                midi.write(midi_file_path)\n",
    "                print(f\"MIDI file saved to: {midi_file_path}\")\n",
    "\n",
    "extract_melody_to_midi('DATA', 'DATA_MIDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_files(midi_folder):\n",
    "    notes = []\n",
    "    for file in os.listdir(midi_folder):\n",
    "        midi = converter.parse(os.path.join(midi_folder, file))\n",
    "        notes_to_parse = None\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                if re.match(r\"[A-G](#|-)?\\d\", str(element.pitch)):\n",
    "                    notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                # Filter each note in the chord\n",
    "                chord_notes = '.'.join(str(n) for n in element.normalOrder if re.match(r\"[A-G](#|-)?\\d\", str(n)))\n",
    "                if chord_notes:\n",
    "                    notes.append(chord_notes)\n",
    "    return notes\n",
    "\n",
    "notes = load_midi_files('indian_classical')\n",
    "# Extract the unique pitches in the dataset\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "# Create a dictionary to map pitches to integers\n",
    "note_to_int = {note: num for num, note in enumerate(pitchnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_files(midi_folder):\n",
    "    notes = []\n",
    "    for file in os.listdir(midi_folder):\n",
    "        midi = converter.parse(os.path.join(midi_folder, file))\n",
    "        notes_to_parse = None\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                if re.match(r\"[A-G](#|-)?\\d\", str(element.pitch)):\n",
    "                    notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                # Filter each note in the chord\n",
    "                chord_notes = '.'.join(str(n) for n in element.normalOrder if re.match(r\"[A-G](#|-)?\\d\", str(n)))\n",
    "                if chord_notes:\n",
    "                    notes.append(chord_notes)\n",
    "    return notes\n",
    "\n",
    "notes = load_midi_files('indian_classical')\n",
    "# Extract the unique pitches in the dataset\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "# Create a dictionary to map pitches to integers\n",
    "note_to_int = {note: num for num, note in enumerate(pitchnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(note_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequences\n",
    "sequence_length = 100\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(len(notes) - sequence_length):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "network_input = np.reshape(network_input, (len(network_input), sequence_length, 1))\n",
    "network_input = torch.tensor(network_input / float(len(pitchnames)), dtype=torch.float32)\n",
    "network_output = torch.tensor(network_output, dtype=torch.long)\n",
    "\n",
    "# Assuming network_input and network_output are already defined\n",
    "train_input, val_input, train_output, val_output = train_test_split(network_input, network_output, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(train_input, train_output)\n",
    "val_dataset = TensorDataset(val_input, val_output)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AdvancedMusicLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AdvancedMusicLSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True, num_layers=2, dropout=0.3)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True, num_layers=2, dropout=0.3)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.batch_norm1(x[:, -1, :])  # Apply batch normalization to the output of the last time step\n",
    "        x, _ = self.lstm2(x.unsqueeze(1))\n",
    "        x = self.batch_norm2(x[:, -1, :])\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = AdvancedMusicLSTM(1, 512, len(pitchnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahat\\miniconda3\\envs\\orc\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bgljpyc9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>3.01493</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-totem-3</strong> at: <a href='https://wandb.ai/rebot/music-generation-3/runs/bgljpyc9' target=\"_blank\">https://wandb.ai/rebot/music-generation-3/runs/bgljpyc9</a><br/> View project at: <a href='https://wandb.ai/rebot/music-generation-3' target=\"_blank\">https://wandb.ai/rebot/music-generation-3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240509_043038-bgljpyc9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bgljpyc9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\SEM6\\DL\\PROJ\\BEGIN\\wandb\\run-20240509_043223-h7z02akz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rebot/music-generation-3/runs/h7z02akz' target=\"_blank\">deep-grass-4</a></strong> to <a href='https://wandb.ai/rebot/music-generation-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rebot/music-generation-3' target=\"_blank\">https://wandb.ai/rebot/music-generation-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rebot/music-generation-3/runs/h7z02akz' target=\"_blank\">https://wandb.ai/rebot/music-generation-3/runs/h7z02akz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 2.991222266227968\n",
      "Validation Phase, Loss: 3.2523501457706576\n",
      "Best model saved with validation loss: 3.2523501457706576\n",
      "Epoch 2/200, Loss: 2.9472225096917923\n",
      "Epoch 3/200, Loss: 2.910635079106977\n",
      "Epoch 4/200, Loss: 2.8864362605156435\n",
      "Epoch 5/200, Loss: 2.860309354720577\n",
      "Epoch 6/200, Loss: 2.8316703977123385\n",
      "Epoch 7/200, Loss: 2.8175263385618887\n",
      "Epoch 8/200, Loss: 2.758324344311991\n",
      "Epoch 9/200, Loss: 2.7206716249066014\n",
      "Epoch 10/200, Loss: 2.7075700356114294\n",
      "Epoch 11/200, Loss: 2.6989801333796595\n",
      "Validation Phase, Loss: 3.979385322140109\n",
      "Epoch 12/200, Loss: 2.670434671063577\n",
      "Epoch 13/200, Loss: 2.66147312425798\n",
      "Epoch 14/200, Loss: 2.6148676122388532\n",
      "Epoch 15/200, Loss: 2.619694244477057\n",
      "Epoch 16/200, Loss: 2.5680073903452967\n",
      "Epoch 17/200, Loss: 2.5584173510151524\n",
      "Epoch 18/200, Loss: 2.5601494293059073\n",
      "Epoch 19/200, Loss: 2.55109824672822\n",
      "Epoch 20/200, Loss: 2.5274645109330454\n",
      "Epoch 21/200, Loss: 2.4983017848383997\n",
      "Validation Phase, Loss: 2.7504618398604856\n",
      "Best model saved with validation loss: 2.7504618398604856\n",
      "Epoch 22/200, Loss: 2.5055526437297946\n",
      "Epoch 23/200, Loss: 2.4906032950647417\n",
      "Epoch 24/200, Loss: 2.473667838881093\n",
      "Epoch 25/200, Loss: 2.4703371178719307\n",
      "Epoch 26/200, Loss: 2.463955433137955\n",
      "Epoch 27/200, Loss: 2.4595329107776767\n",
      "Epoch 28/200, Loss: 2.4528883907102768\n",
      "Epoch 29/200, Loss: 2.4433288997219456\n",
      "Epoch 30/200, Loss: 2.442605872308054\n",
      "Epoch 31/200, Loss: 2.4271015409500367\n",
      "Validation Phase, Loss: 2.686263730449061\n",
      "Best model saved with validation loss: 2.686263730449061\n",
      "Epoch 32/200, Loss: 2.4149458023809616\n",
      "Epoch 33/200, Loss: 2.42750758124936\n",
      "Epoch 34/200, Loss: 2.4289309363211355\n",
      "Epoch 35/200, Loss: 2.4173931825545525\n",
      "Epoch 36/200, Loss: 2.4084839147906147\n",
      "Epoch 37/200, Loss: 2.396539009386493\n",
      "Epoch 38/200, Loss: 2.3823612178525617\n",
      "Epoch 39/200, Loss: 2.4000886044194623\n",
      "Epoch 40/200, Loss: 2.3856225109869436\n",
      "Epoch 41/200, Loss: 2.3874810741793726\n",
      "Validation Phase, Loss: 2.608202642010104\n",
      "Best model saved with validation loss: 2.608202642010104\n",
      "Epoch 42/200, Loss: 2.3930674618290317\n",
      "Epoch 43/200, Loss: 2.3882308640787677\n",
      "Epoch 44/200, Loss: 2.359148571568151\n",
      "Epoch 45/200, Loss: 2.3623036011572807\n",
      "Epoch 46/200, Loss: 2.3725487272585593\n",
      "Epoch 47/200, Loss: 2.3848600349118634\n",
      "Epoch 48/200, Loss: 2.3513866893706785\n",
      "Epoch 49/200, Loss: 2.3470191272997085\n",
      "Epoch 50/200, Loss: 2.3594265368676957\n",
      "Epoch 51/200, Loss: 2.349891035787521\n",
      "Validation Phase, Loss: 2.603040702881352\n",
      "Best model saved with validation loss: 2.603040702881352\n",
      "Epoch 52/200, Loss: 2.3732755799447336\n",
      "Epoch 53/200, Loss: 2.3459002615944033\n",
      "Epoch 54/200, Loss: 2.337270542498558\n",
      "Epoch 55/200, Loss: 2.3404781837617197\n",
      "Epoch 56/200, Loss: 2.357488520683781\n",
      "Epoch 57/200, Loss: 2.3405714861808287\n",
      "Epoch 58/200, Loss: 2.3373204873454188\n",
      "Epoch 59/200, Loss: 2.3505973392917263\n",
      "Epoch 60/200, Loss: 2.337867121542654\n",
      "Epoch 61/200, Loss: 2.341547103658799\n",
      "Validation Phase, Loss: 2.611881502213017\n",
      "Epoch 62/200, Loss: 2.3453395443577922\n",
      "Epoch 63/200, Loss: 2.3352300274756645\n",
      "Epoch 64/200, Loss: 2.3443496640651458\n",
      "Epoch 65/200, Loss: 2.34697364991711\n",
      "Epoch 66/200, Loss: 2.3367818209432785\n",
      "Epoch 67/200, Loss: 2.3530026655043326\n",
      "Epoch 68/200, Loss: 2.3378168363724985\n",
      "Epoch 69/200, Loss: 2.330092268605386\n",
      "Epoch 70/200, Loss: 2.3440437115007833\n",
      "Epoch 71/200, Loss: 2.3507252623957973\n",
      "Validation Phase, Loss: 2.6003817204506166\n",
      "Best model saved with validation loss: 2.6003817204506166\n",
      "Epoch 72/200, Loss: 2.3406725179764534\n",
      "Epoch 73/200, Loss: 2.3245717652382387\n",
      "Epoch 74/200, Loss: 2.353021965872857\n",
      "Epoch 75/200, Loss: 2.3376466766480477\n",
      "Epoch 76/200, Loss: 2.338699298520242\n",
      "Epoch 77/200, Loss: 2.3210694020794285\n",
      "Epoch 78/200, Loss: 2.3375474339531315\n",
      "Epoch 79/200, Loss: 2.3340242428164326\n",
      "Epoch 80/200, Loss: 2.3326824615078587\n",
      "Epoch 81/200, Loss: 2.338444250245248\n",
      "Validation Phase, Loss: 2.596109974768854\n",
      "Best model saved with validation loss: 2.596109974768854\n",
      "Epoch 82/200, Loss: 2.3261669951100505\n",
      "Epoch 83/200, Loss: 2.3298766343824324\n",
      "Epoch 84/200, Loss: 2.3152734137350515\n",
      "Epoch 85/200, Loss: 2.334555697056555\n",
      "Epoch 86/200, Loss: 2.3280690610408783\n",
      "Epoch 87/200, Loss: 2.349613135860812\n",
      "Epoch 88/200, Loss: 2.336245290694698\n",
      "Epoch 89/200, Loss: 2.3388298355763957\n",
      "Epoch 90/200, Loss: 2.3434123435328083\n",
      "Epoch 91/200, Loss: 2.321271183029298\n",
      "Validation Phase, Loss: 2.599997389701105\n",
      "Epoch 92/200, Loss: 2.3379048349395877\n",
      "Epoch 93/200, Loss: 2.327724786535386\n",
      "Epoch 94/200, Loss: 2.333726792566238\n",
      "Epoch 95/200, Loss: 2.3454116025278644\n",
      "Epoch 96/200, Loss: 2.3385169217663426\n",
      "Epoch 97/200, Loss: 2.33166850766828\n",
      "Epoch 98/200, Loss: 2.3314874191437998\n",
      "Epoch 99/200, Loss: 2.3177605261725764\n",
      "Epoch 100/200, Loss: 2.347312363886064\n",
      "Epoch 101/200, Loss: 2.3449261544212217\n",
      "Validation Phase, Loss: 2.608093238645984\n",
      "Epoch 102/200, Loss: 2.3341206754407575\n",
      "Epoch 103/200, Loss: 2.338535216546828\n",
      "Epoch 104/200, Loss: 2.3322233644223984\n",
      "Epoch 105/200, Loss: 2.346909031752617\n",
      "Epoch 106/200, Loss: 2.3569282581729274\n",
      "Epoch 107/200, Loss: 2.3265917397314504\n",
      "Epoch 108/200, Loss: 2.3298391257562945\n",
      "Epoch 109/200, Loss: 2.329798859934653\n",
      "Epoch 110/200, Loss: 2.344970892513952\n",
      "Epoch 111/200, Loss: 2.328004555356118\n",
      "Validation Phase, Loss: 2.5918931268876597\n",
      "Best model saved with validation loss: 2.5918931268876597\n",
      "Epoch 112/200, Loss: 2.343944413046683\n",
      "Epoch 113/200, Loss: 2.3343983638671135\n",
      "Epoch 114/200, Loss: 2.3303532331220564\n",
      "Epoch 115/200, Loss: 2.3288578544893572\n",
      "Epoch 116/200, Loss: 2.3461538591692523\n",
      "Epoch 117/200, Loss: 2.3204080087523304\n",
      "Epoch 118/200, Loss: 2.3406287056784474\n",
      "Epoch 119/200, Loss: 2.328606661288969\n",
      "Epoch 120/200, Loss: 2.325687538231573\n",
      "Epoch 121/200, Loss: 2.319424698429723\n",
      "Validation Phase, Loss: 2.599606521667973\n",
      "Epoch 122/200, Loss: 2.339879910792074\n",
      "Epoch 123/200, Loss: 2.32651009098176\n",
      "Epoch 124/200, Loss: 2.3298809662941964\n",
      "Epoch 125/200, Loss: 2.3406435943418935\n",
      "Epoch 126/200, Loss: 2.3232355367752815\n",
      "Epoch 127/200, Loss: 2.32178948579296\n",
      "Epoch 128/200, Loss: 2.333830525798182\n",
      "Epoch 129/200, Loss: 2.323785355975551\n",
      "Epoch 130/200, Loss: 2.3353330694860026\n",
      "Epoch 131/200, Loss: 2.327956219834666\n",
      "Validation Phase, Loss: 2.596726071450018\n",
      "Epoch 132/200, Loss: 2.3184956523679916\n",
      "Epoch 133/200, Loss: 2.3448410476407697\n",
      "Epoch 134/200, Loss: 2.3465901661303734\n",
      "Epoch 135/200, Loss: 2.3361449481979495\n",
      "Epoch 136/200, Loss: 2.323939584916638\n",
      "Epoch 137/200, Loss: 2.347353259401937\n",
      "Epoch 138/200, Loss: 2.3368004916175718\n",
      "Epoch 139/200, Loss: 2.32913895768504\n",
      "Epoch 140/200, Loss: 2.3463021901346024\n",
      "Epoch 141/200, Loss: 2.333598655077719\n",
      "Validation Phase, Loss: 2.5972221512948312\n",
      "Epoch 142/200, Loss: 2.3217453745103653\n",
      "Epoch 143/200, Loss: 2.3274693931302717\n",
      "Epoch 144/200, Loss: 2.3203037390785832\n",
      "Epoch 145/200, Loss: 2.32428035043901\n",
      "Epoch 146/200, Loss: 2.337903728408198\n",
      "Epoch 147/200, Loss: 2.3260743118101552\n",
      "Epoch 148/200, Loss: 2.3484893325836427\n",
      "Epoch 149/200, Loss: 2.319176233583881\n",
      "Epoch 150/200, Loss: 2.3360484155916397\n",
      "Epoch 151/200, Loss: 2.3328731415733213\n",
      "Validation Phase, Loss: 2.598988602238317\n",
      "Epoch 152/200, Loss: 2.3229679676794235\n",
      "Epoch 153/200, Loss: 2.337086296850635\n",
      "Epoch 154/200, Loss: 2.3316424556316866\n",
      "Epoch 155/200, Loss: 2.3458764130069363\n",
      "Epoch 156/200, Loss: 2.3196610145030485\n",
      "Epoch 157/200, Loss: 2.3288693389584942\n",
      "Epoch 158/200, Loss: 2.329623946259099\n",
      "Epoch 159/200, Loss: 2.355545179497811\n",
      "Epoch 160/200, Loss: 2.337450356252732\n",
      "Epoch 161/200, Loss: 2.3224825695637734\n",
      "Validation Phase, Loss: 2.5936516792543474\n",
      "Epoch 162/200, Loss: 2.339208080883949\n",
      "Epoch 163/200, Loss: 2.3311012829503706\n",
      "Epoch 164/200, Loss: 2.329207120403167\n",
      "Epoch 165/200, Loss: 2.3232672099144227\n",
      "Epoch 166/200, Loss: 2.339439781442765\n",
      "Epoch 167/200, Loss: 2.333275489268764\n",
      "Epoch 168/200, Loss: 2.321652950779084\n",
      "Epoch 169/200, Loss: 2.3172822142800977\n",
      "Epoch 170/200, Loss: 2.33563736754079\n",
      "Epoch 171/200, Loss: 2.337589450420872\n",
      "Validation Phase, Loss: 2.5955101136238343\n",
      "Epoch 172/200, Loss: 2.3380892440196006\n",
      "Epoch 173/200, Loss: 2.328190376681666\n",
      "Epoch 174/200, Loss: 2.348613231412826\n",
      "Epoch 175/200, Loss: 2.3477065044064678\n",
      "Epoch 176/200, Loss: 2.3268207119357203\n",
      "Epoch 177/200, Loss: 2.321624866416377\n",
      "Epoch 178/200, Loss: 2.323786470197862\n",
      "Epoch 179/200, Loss: 2.3509002193327873\n",
      "Epoch 180/200, Loss: 2.3470649853829415\n",
      "Epoch 181/200, Loss: 2.3337744118705874\n",
      "Validation Phase, Loss: 2.5923285715041624\n",
      "Epoch 182/200, Loss: 2.3230417015091067\n",
      "Epoch 183/200, Loss: 2.332650463427267\n",
      "Epoch 184/200, Loss: 2.3414481820598727\n",
      "Epoch 185/200, Loss: 2.3345283279495854\n",
      "Epoch 186/200, Loss: 2.326272477065363\n",
      "Epoch 187/200, Loss: 2.3382155904846806\n",
      "Epoch 188/200, Loss: 2.351236170338046\n",
      "Epoch 189/200, Loss: 2.3412520548989697\n",
      "Epoch 190/200, Loss: 2.3379337576127823\n",
      "Epoch 191/200, Loss: 2.3130198851708443\n",
      "Validation Phase, Loss: 2.6004163680538053\n",
      "Epoch 192/200, Loss: 2.3395203544247534\n",
      "Epoch 193/200, Loss: 2.3401311347561498\n",
      "Epoch 194/200, Loss: 2.3395101120395045\n",
      "Epoch 195/200, Loss: 2.3291421186539436\n",
      "Epoch 196/200, Loss: 2.326003377476046\n",
      "Epoch 197/200, Loss: 2.330096898540374\n",
      "Epoch 198/200, Loss: 2.340831441263999\n",
      "Epoch 199/200, Loss: 2.323026410994991\n",
      "Epoch 200/200, Loss: 2.3232578731352285\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def train_model_with_checkpoint(model, dataloader, validation_dataloader, epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    criterion = nn.NLLLoss()  # Using NLLLoss which is suitable for LogSoftmax\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    wandb.init(project=\"music-generation-3\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss}')\n",
    "        wandb.log({\"epoch\": epoch + 1, \"loss\": avg_train_loss})\n",
    "\n",
    "        # Validation phase\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validation_dataloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "            avg_val_loss = val_loss / len(validation_dataloader)\n",
    "            print(f'Validation Phase, Loss: {avg_val_loss}')\n",
    "            wandb.log({\"Validation loss\" : avg_val_loss})\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Checkpoint model\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'three-best_model.pth')\n",
    "            print(f'Best model saved with validation loss: {best_loss}')\n",
    "\n",
    "train_model_with_checkpoint(model, train_dataloader, validation_dataloader, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'AdvancedMusicLSTM' is the class of your model\n",
    "model = AdvancedMusicLSTM(input_size=1, hidden_size=512, output_size=len(pitchnames))  # Adjust parameters as necessary\n",
    "\n",
    "# Load the model state\n",
    "model_path = 'best_model.pth'  # Replace with your actual model path\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "def generate_music(model, network_input, pitchnames, note_to_int, num_generate=500):\n",
    "    \"\"\" Generate music given a sequence of notes \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Pick a random sequence from the input as a starting point for the generation\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "    int_to_note = {num: note for note, num in note_to_int.items()}\n",
    "    pattern = network_input[start].numpy().flatten().tolist()  # Ensure pattern is a list of integers\n",
    "\n",
    "    prediction_output = []\n",
    "\n",
    "    # Generate notes\n",
    "    for note_index in range(num_generate):\n",
    "        # Convert pattern to tensor and ensure it is in the correct shape\n",
    "        prediction_input = torch.tensor([pattern], dtype=torch.float32).unsqueeze(-1).to(device)  # Add an extra dimension\n",
    "        prediction = model(prediction_input)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        \n",
    "        result = int_to_note[index.item()]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        # Update pattern by appending the new index and removing the first element\n",
    "        pattern.append(index.item())\n",
    "        pattern = pattern[1:]  # Ensure pattern remains a list of integers\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "# Generate a piece of music\n",
    "generated_notes = generate_music(model, network_input, pitchnames, note_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note, chord, midi\n",
    "\n",
    "def create_midi(prediction_output, output_path='output.mid'):\n",
    "    \"\"\" Convert the output from the prediction to MIDI file \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # Create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # Pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # Pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # Increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=output_path)\n",
    "\n",
    "# Create a MIDI file from the generated notes\n",
    "create_midi(generated_notes, '2-out.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
